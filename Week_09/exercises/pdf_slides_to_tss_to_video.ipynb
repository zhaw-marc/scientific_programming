{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b0459c0",
   "metadata": {},
   "source": [
    "# PDF Slides -> Text to Speech (TTS) -> Video Workflow\n",
    "\n",
    "This notebook converts a **PDF (one page = one slide)** into a narrated video.\n",
    "\n",
    "**Workflow (what the code does):**\n",
    "- Input: PDF file\n",
    "- Render: Create exactly one image per PDF page\n",
    "- Extract text: Read per-page text via PyMuPDF; if too short/empty, use OCR as fallback\n",
    "- Summarize: The LLM generates speaker narration for exactly one slide at a time**\n",
    "- Speak: Create per-slide audio via OpenAI TTS\n",
    "- Video: Combine slide images + per-slide audio into a single MP4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0e9f9a",
   "metadata": {},
   "source": [
    "## Libraries and API-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea97a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from moviepy import AudioFileClip, ImageClip, concatenate_videoclips\n",
    "\n",
    "# Load .env File\n",
    "dotenv_path = find_dotenv(usecwd=True)\n",
    "if dotenv_path:\n",
    "    load_dotenv(dotenv_path)\n",
    "    print(f\"Loaded .env from: {dotenv_path}\")\n",
    "else:\n",
    "    print(\"No .env file found (please create one with your OPENAI_API_KEY).\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f\"OPENAI_API_KEY set: {bool(OPENAI_API_KEY)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a598feaf",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b083dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIG ---\n",
    "INPUT_PDF_PATH = \"data/Week_08_SP_Slides_4_5_6.pdf\"\n",
    "OUTPUT_VIDEO = \"final_video.mp4\"\n",
    "TEMP_DIR = \"temp_assets\"\n",
    "\n",
    "# Output language: EN, IT, FR, DE, ES\n",
    "OUTPUT_LANG = \"EN\"\n",
    "\n",
    "# Target minutes spoken per PDF page\n",
    "TARGET_SPOKEN_MINUTES_PER_PAGE = 1\n",
    "\n",
    "# Detail style: \"summary\" or \"detailed\"\n",
    "DETAIL_STYLE = \"summary\"\n",
    "\n",
    "# Estimated words per minute\n",
    "SPEECH_WPM = 150\n",
    "\n",
    "# Silent fallback when no API key is set\n",
    "DEFAULT_PAGE_SECONDS = 5\n",
    "\n",
    "# Render settings\n",
    "PDF_DPI = 200\n",
    "IMAGE_FORMAT = \"jpg\"  # jpg or png\n",
    "IMAGE_QUALITY = 92  # used for jpg\n",
    "CLEAN_OUTPUT_DIRS = True\n",
    "\n",
    "# Optional slide range (1-indexed, inclusive). Use None for \"until end\"\n",
    "SLIDE_START = 1\n",
    "SLIDE_END = None\n",
    "\n",
    "# OCR fallback (used when extracted text is empty/too short)\n",
    "OCR_FALLBACK = True\n",
    "OCR_MIN_TEXT_CHARS = 30\n",
    "\n",
    "# TTS settings\n",
    "TTS_MODEL = \"gpt-4o-mini-tts\"\n",
    "TTS_VOICE = \"alloy\"  # alloy, echo, fable, onyx, nova, shimmer\n",
    "\n",
    "# Save per-slide narration text\n",
    "SAVE_SLIDE_TEXT = True\n",
    "\n",
    "# --- NEW: script source selection (yes/no) ---\n",
    "# If \"yes\": use user-corrected narration text if available.\n",
    "# If \"no\": use the original LLM narration text.\n",
    "USE_USER_CORRECTED_TEXT = \"no\"  # yes/no\n",
    "\n",
    "# If \"no\": reuse existing LLM original scripts (no re-generation).\n",
    "# If \"yes\": regenerate LLM scripts (originals are versioned; never overwritten).\n",
    "FORCE_REGENERATE_LLM_TEXT = \"no\"  # yes/no\n",
    "\n",
    "# If \"yes\": when a user-corrected script is missing, create a template from the LLM script\n",
    "CREATE_USER_CORRECTION_TEMPLATES = \"yes\"  # yes/no\n",
    "\n",
    "# Script folders under TEMP_DIR\n",
    "LLM_SCRIPTS_SUBDIR = \"scripts_llm_original\"\n",
    "USER_SCRIPTS_SUBDIR = \"scripts_user_corrected\"\n",
    "USED_SCRIPTS_SUBDIR = \"scripts_used\"\n",
    "\n",
    "# Language maps\n",
    "LANG_MAP = {\n",
    "    \"EN\": \"English\",\n",
    "    \"DE\": \"German\",\n",
    "    \"FR\": \"French\",\n",
    "    \"IT\": \"Italian\",\n",
    "    \"ES\": \"Spanish\",\n",
    "}\n",
    "TESSERACT_LANG_MAP = {\n",
    "    \"EN\": \"eng\",\n",
    "    \"DE\": \"deu\",\n",
    "    \"FR\": \"fra\",\n",
    "    \"IT\": \"ita\",\n",
    "    \"ES\": \"spa\",\n",
    "}\n",
    "\n",
    "# Audio sample rate (used for silent fallback audio)\n",
    "AUDIO_MP3_FPS = 44100\n",
    "\n",
    "# MP4 encoding options (slides + audio)\n",
    "VIDEO_FPS = 24\n",
    "VIDEO_CODEC = \"libx264\"\n",
    "VIDEO_AUDIO_CODEC = \"aac\"\n",
    "VIDEO_TARGET_W = 1280\n",
    "VIDEO_TARGET_H = 720\n",
    "VIDEO_FFMPEG_VF = (\n",
    "    f\"scale={VIDEO_TARGET_W}:{VIDEO_TARGET_H}:force_original_aspect_ratio=decrease,\"\n",
    "    f\"pad={VIDEO_TARGET_W}:{VIDEO_TARGET_H}:(ow-iw)/2:(oh-ih)/2,setsar=1\"\n",
    " )\n",
    "VIDEO_FFMPEG_PARAMS = [\n",
    "    \"-movflags\",\n",
    "    \"+faststart\",\n",
    "    \"-vf\",\n",
    "    VIDEO_FFMPEG_VF,\n",
    "    \"-pix_fmt\",\n",
    "    \"yuv420p\",\n",
    "    \"-profile:v\",\n",
    "    \"baseline\",\n",
    "    \"-level\",\n",
    "    \"3.1\",\n",
    "]\n",
    "\n",
    "# Auto-run at end of notebook\n",
    "RUN_WORKFLOW = True\n",
    "\n",
    "# Ensure temp dir exists\n",
    "Path(TEMP_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# OpenAI is optional\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "USE_OPENAI = bool(OPENAI_API_KEY)\n",
    "\n",
    "client = None\n",
    "if USE_OPENAI:\n",
    "    try:\n",
    "        from openai import OpenAI  # openai>=1.x\n",
    "\n",
    "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    except Exception as exc:\n",
    "        raise RuntimeError(\n",
    "            \"OpenAI client import failed. Install/upgrade with: pip install -U openai\"\n",
    "        ) from exc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf4303c",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3751e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_lang(lang: str) -> str:\n",
    "    if not isinstance(lang, str) or not lang.strip():\n",
    "        raise ValueError(\"OUTPUT_LANG must be a non-empty string (e.g. 'EN').\")\n",
    "\n",
    "    code = lang.strip().upper()\n",
    "    aliases = {\n",
    "        \"GERMAN\": \"DE\",\n",
    "        \"DEUTSCH\": \"DE\",\n",
    "        \"ENGLISH\": \"EN\",\n",
    "        \"ITALIAN\": \"IT\",\n",
    "        \"ITALIANO\": \"IT\",\n",
    "        \"FRENCH\": \"FR\",\n",
    "        \"FRANCAIS\": \"FR\",\n",
    "        \"FRANÇAIS\": \"FR\",\n",
    "        \"SPANISH\": \"ES\",\n",
    "        \"ESPANOL\": \"ES\",\n",
    "        \"ESPAÑOL\": \"ES\",\n",
    "    }\n",
    "    code = aliases.get(code, code)\n",
    "\n",
    "    if code not in LANG_MAP:\n",
    "        supported = \", \".join(sorted(LANG_MAP.keys()))\n",
    "        raise ValueError(f\"Unsupported OUTPUT_LANG='{lang}'. Supported: {supported}\")\n",
    "\n",
    "    return code\n",
    "\n",
    "\n",
    "def parse_yes_no(value, default: bool = False) -> bool:\n",
    "    if isinstance(value, bool):\n",
    "        return value\n",
    "    if value is None:\n",
    "        return default\n",
    "\n",
    "    s = str(value).strip().lower()\n",
    "    if s in {\"y\", \"yes\", \"true\", \"1\", \"on\"}:\n",
    "        return True\n",
    "    if s in {\"n\", \"no\", \"false\", \"0\", \"off\"}:\n",
    "        return False\n",
    "\n",
    "    return default\n",
    "\n",
    "\n",
    "def clamp_minutes(minutes) -> float:\n",
    "    try:\n",
    "        value = float(minutes)\n",
    "    except Exception as exc:\n",
    "        raise ValueError(\n",
    "            \"TARGET_SPOKEN_MINUTES_PER_PAGE must be a number (e.g. 1 or 5).\"\n",
    "        ) from exc\n",
    "\n",
    "    if value <= 0:\n",
    "        raise ValueError(\"TARGET_SPOKEN_MINUTES_PER_PAGE must be > 0\")\n",
    "\n",
    "    return value\n",
    "\n",
    "\n",
    "def max_words_for_minutes(minutes: float, wpm: int = 150) -> int:\n",
    "    return max(30, int(round(minutes * wpm)))\n",
    "\n",
    "\n",
    "def truncate_to_word_limit(text: str, max_words: int) -> str:\n",
    "    words = text.split()\n",
    "    if len(words) <= max_words:\n",
    "        return text\n",
    "    return \" \".join(words[:max_words]).rstrip() + \"…\"\n",
    "\n",
    "\n",
    "def clean_page_text(page_text: str) -> str:\n",
    "    \"\"\"Light cleanup to avoid headers/footers like 'Page 3' confusing the model.\"\"\"\n",
    "    if not isinstance(page_text, str):\n",
    "        return \"\"\n",
    "\n",
    "    lines = [ln.strip() for ln in page_text.splitlines()]\n",
    "    cleaned: list[str] = []\n",
    "    for ln in lines:\n",
    "        if not ln:\n",
    "            continue\n",
    "        # Drop very short page markers (common PDF footer/header artifacts)\n",
    "        if re.fullmatch(r\"(?i)page\\s*\\d+(\\s*of\\s*\\d+)?\", ln) and len(ln) <= 20:\n",
    "            continue\n",
    "        if re.fullmatch(r\"\\d+\\s*/\\s*\\d+\", ln) and len(ln) <= 10:\n",
    "            continue\n",
    "        cleaned.append(ln)\n",
    "\n",
    "    text = \"\\n\".join(cleaned)\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def sanitize_script_output(text: str) -> str:\n",
    "    \"\"\"Remove common unwanted 'meta' prefixes and multi-page style markers.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    t = text.strip()\n",
    "    t = re.sub(r\"(?is)^(slide|page)\\s*\\d+(\\s*(/|of)\\s*\\d+)?\\s*:\\s*\", \"\", t)\n",
    "    t = re.sub(r\"(?is)^(speaker\\s*notes?|narration|script)\\s*:\\s*\", \"\", t)\n",
    "    t = re.sub(r\"(?im)^\\s*(continued|continue)\\s*\\.?\\s*$\", \"\", t)\n",
    "    t = re.sub(r\"(?im)^\\s*(next\\s+slide|on\\s+the\\s+next\\s+slide)\\b.*$\", \"\", t)\n",
    "    t = re.sub(r\"\\n{3,}\", \"\\n\\n\", t).strip()\n",
    "    return t\n",
    "\n",
    "\n",
    "def normalize_detail_style(style: str) -> str:\n",
    "    if not isinstance(style, str) or not style.strip():\n",
    "        return \"summary\"\n",
    "\n",
    "    normalized = style.strip().lower()\n",
    "    if normalized in {\"summary\", \"summarize\", \"short\", \"brief\"}:\n",
    "        return \"summary\"\n",
    "    if normalized in {\"detailed\", \"detail\", \"long\"}:\n",
    "        return \"detailed\"\n",
    "\n",
    "    raise ValueError(\"DETAIL_STYLE must be one of: 'summary', 'detailed'\")\n",
    "\n",
    "\n",
    "def clamp_slide_range(start: int | None, end: int | None, total_pages: int) -> tuple[int, int]:\n",
    "    if start is None:\n",
    "        start = 1\n",
    "    if end is None:\n",
    "        end = total_pages\n",
    "\n",
    "    if start < 1 or end < 1 or start > end:\n",
    "        raise ValueError(f\"Invalid slide range: start={start}, end={end}\")\n",
    "    if start > total_pages:\n",
    "        raise ValueError(f\"SLIDE_START={start} exceeds total pages={total_pages}\")\n",
    "    end = min(end, total_pages)\n",
    "    return start, end\n",
    "\n",
    "\n",
    "def clear_dir_by_patterns(dir_path: Path, patterns: list[str]) -> None:\n",
    "    if not dir_path.exists():\n",
    "        return\n",
    "    for pattern in patterns:\n",
    "        for p in dir_path.glob(pattern):\n",
    "            try:\n",
    "                if p.is_file():\n",
    "                    p.unlink()\n",
    "            except OSError:\n",
    "                pass\n",
    "\n",
    "\n",
    "def safe_write_text_no_overwrite(path: Path, text: str, encoding: str = \"utf-8\") -> Path:\n",
    "    \"\"\"Write text but never overwrite an existing file.\n",
    "\n",
    "    If the target exists with identical content, keep it.\n",
    "    If it exists with different content, write a versioned sibling (e.g. __v001).\n",
    "    \"\"\"\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if path.exists():\n",
    "        try:\n",
    "            existing = path.read_text(encoding=encoding)\n",
    "            if existing == text:\n",
    "                return path\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "        stem = path.stem\n",
    "        suffix = path.suffix\n",
    "        for k in range(1, 1000):\n",
    "            candidate = path.with_name(f\"{stem}__v{k:03d}{suffix}\")\n",
    "            if not candidate.exists():\n",
    "                candidate.write_text(text, encoding=encoding)\n",
    "                return candidate\n",
    "\n",
    "        raise RuntimeError(f\"Too many versions for {path.name}\")\n",
    "\n",
    "    path.write_text(text, encoding=encoding)\n",
    "    return path\n",
    "\n",
    "\n",
    "def read_text_or_empty(path: Path, encoding: str = \"utf-8\") -> str:\n",
    "    try:\n",
    "        if path.exists() and path.is_file():\n",
    "            return path.read_text(encoding=encoding)\n",
    "    except OSError:\n",
    "        return \"\"\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def render_pdf_pages_to_images_pymupdf(\n",
    "    pdf_path: str,\n",
    "    out_dir: str,\n",
    "    dpi: int = 200,\n",
    "    slide_start: int | None = None,\n",
    "    slide_end: int | None = None,\n",
    "    image_format: str = \"jpg\",\n",
    "    jpg_quality: int = 92,\n",
    ") -> list[Path]:\n",
    "    \"\"\"Render exactly one image per PDF page using PyMuPDF (fitz).\"\"\"\n",
    "    try:\n",
    "        import fitz  # PyMuPDF\n",
    "    except Exception as exc:\n",
    "        raise RuntimeError(\n",
    "            \"PyMuPDF is required for rendering. Install with: pip install pymupdf\"\n",
    "        ) from exc\n",
    "\n",
    "    pdf_path = str(Path(pdf_path).resolve())\n",
    "    out_dir_path = Path(out_dir).resolve()\n",
    "    out_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if CLEAN_OUTPUT_DIRS:\n",
    "        clear_dir_by_patterns(\n",
    "            out_dir_path,\n",
    "            [\n",
    "                \"slide_*.jpg\",\n",
    "                \"slide_*.png\",\n",
    "                \"page_*.jpg\",\n",
    "                \"page_*.png\",\n",
    "                \"Slide*.JPG\",\n",
    "                \"Slide*.PNG\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    doc = fitz.open(pdf_path)\n",
    "    total_pages = doc.page_count\n",
    "    start, end = clamp_slide_range(slide_start, slide_end, total_pages)\n",
    "\n",
    "    zoom = dpi / 72.0\n",
    "    matrix = fitz.Matrix(zoom, zoom)\n",
    "\n",
    "    paths: list[Path] = []\n",
    "    try:\n",
    "        for page_no in range(start - 1, end):\n",
    "            page = doc.load_page(page_no)\n",
    "            pix = page.get_pixmap(matrix=matrix, alpha=False)\n",
    "\n",
    "            out_path = out_dir_path / f\"slide_{page_no + 1:03d}.{image_format.lower()}\"\n",
    "            if image_format.lower() == \"png\":\n",
    "                pix.save(str(out_path))\n",
    "            elif image_format.lower() == \"jpg\":\n",
    "                pix.save(str(out_path), output=\"jpeg\", jpg_quality=int(jpg_quality))\n",
    "            else:\n",
    "                raise ValueError(\"IMAGE_FORMAT must be 'jpg' or 'png'\")\n",
    "\n",
    "            paths.append(out_path)\n",
    "    finally:\n",
    "        doc.close()\n",
    "\n",
    "    if not paths:\n",
    "        raise RuntimeError(\"No images produced from PDF.\")\n",
    "\n",
    "    return paths\n",
    "\n",
    "\n",
    "def get_pdf_page_texts_pymupdf(pdf_path: str, slide_start: int, slide_end: int) -> list[str]:\n",
    "    \"\"\"Extract text per PDF page via PyMuPDF. Often better than PyPDF2.\"\"\"\n",
    "    try:\n",
    "        import fitz  # PyMuPDF\n",
    "    except Exception as exc:\n",
    "        raise RuntimeError(\n",
    "            \"PyMuPDF is required for text extraction. Install with: pip install pymupdf\"\n",
    "        ) from exc\n",
    "\n",
    "    pdf_path = str(Path(pdf_path).resolve())\n",
    "    doc = fitz.open(pdf_path)\n",
    "    total_pages = doc.page_count\n",
    "    start, end = clamp_slide_range(slide_start, slide_end, total_pages)\n",
    "\n",
    "    texts: list[str] = []\n",
    "    try:\n",
    "        for page_no in range(start - 1, end):\n",
    "            page = doc.load_page(page_no)\n",
    "            text = page.get_text(\"text\") or \"\"\n",
    "            texts.append(clean_page_text(text))\n",
    "    finally:\n",
    "        doc.close()\n",
    "\n",
    "    return texts\n",
    "\n",
    "\n",
    "def ocr_image_text(image_path: Path, output_lang: str) -> str:\n",
    "    \"\"\"OCR an image with pytesseract. Requires the Tesseract binary installed on the machine.\"\"\"\n",
    "    try:\n",
    "        import pytesseract\n",
    "        from PIL import Image\n",
    "    except Exception as exc:\n",
    "        raise RuntimeError(\n",
    "            \"OCR dependencies missing. Install with: pip install pytesseract pillow\"\n",
    "        ) from exc\n",
    "\n",
    "    lang_code = normalize_lang(output_lang)\n",
    "    tesseract_lang = TESSERACT_LANG_MAP.get(lang_code, \"eng\")\n",
    "\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        text = pytesseract.image_to_string(img, lang=tesseract_lang) or \"\"\n",
    "        return clean_page_text(text)\n",
    "    except Exception as exc:\n",
    "        raise RuntimeError(\n",
    "            \"OCR failed. Ensure Tesseract OCR is installed and available on PATH. \"\n",
    "            \"On Windows you can install it and (optionally) set pytesseract.pytesseract.tesseract_cmd.\"\n",
    "        ) from exc\n",
    "\n",
    "\n",
    "def get_slide_texts_with_ocr_fallback(\n",
    "    pdf_path: str,\n",
    "    slide_images: list[Path],\n",
    "    slide_start: int,\n",
    "    slide_end: int,\n",
    "    output_lang: str,\n",
    ") -> list[str]:\n",
    "    extracted = get_pdf_page_texts_pymupdf(pdf_path, slide_start=slide_start, slide_end=slide_end)\n",
    "\n",
    "    # Safety: keep lengths aligned\n",
    "    if len(extracted) < len(slide_images):\n",
    "        extracted.extend([\"\"] * (len(slide_images) - len(extracted)))\n",
    "    elif len(extracted) > len(slide_images):\n",
    "        extracted = extracted[: len(slide_images)]\n",
    "\n",
    "    if not OCR_FALLBACK:\n",
    "        return extracted\n",
    "\n",
    "    out: list[str] = []\n",
    "    for i, img_path in enumerate(slide_images):\n",
    "        text = extracted[i]\n",
    "        if len(text.strip()) >= OCR_MIN_TEXT_CHARS:\n",
    "            out.append(text)\n",
    "            continue\n",
    "\n",
    "        # OCR fallback if text is empty/too short\n",
    "        try:\n",
    "            ocr_text = ocr_image_text(img_path, output_lang=output_lang)\n",
    "        except Exception as exc:\n",
    "            print(f\"OCR warning for {img_path.name}: {exc}\")\n",
    "            ocr_text = \"\"\n",
    "\n",
    "        out.append(ocr_text if len(ocr_text.strip()) > len(text.strip()) else text)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def _norm_compact(s: str) -> str:\n",
    "    s = s or \"\"\n",
    "    s = s.strip().lower()\n",
    "    s = re.sub(r\"[^a-z0-9]+\", \"\", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def detect_slide_headline(slide_text: str) -> str | None:\n",
    "    \"\"\"Best-effort headline detection from extracted slide text (first non-bullet short line).\"\"\"\n",
    "    if not isinstance(slide_text, str):\n",
    "        return None\n",
    "\n",
    "    lines = [ln.strip() for ln in slide_text.splitlines() if ln.strip()]\n",
    "    if not lines:\n",
    "        return None\n",
    "\n",
    "    for ln in lines[:3]:\n",
    "        if len(ln) > 90:\n",
    "            continue\n",
    "        if ln.startswith((\"-\", \"•\", \"*\")):\n",
    "            continue\n",
    "        if re.match(r\"^\\d+[.)]\\s+\", ln):\n",
    "            continue\n",
    "        if len(ln) < 4:\n",
    "            continue\n",
    "        return ln\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def remove_headline_line(slide_text: str, headline: str | None) -> str:\n",
    "    if not headline or not isinstance(slide_text, str):\n",
    "        return slide_text or \"\"\n",
    "\n",
    "    target = _norm_compact(headline)\n",
    "    if not target:\n",
    "        return slide_text\n",
    "\n",
    "    out_lines: list[str] = []\n",
    "    removed = False\n",
    "    for ln in slide_text.splitlines():\n",
    "        if not removed and _norm_compact(ln) == target:\n",
    "            removed = True\n",
    "            continue\n",
    "        out_lines.append(ln)\n",
    "\n",
    "    return clean_page_text(\"\\n\".join(out_lines))\n",
    "\n",
    "\n",
    "def remove_headline_echo(script: str, headline: str | None) -> str:\n",
    "    if not headline or not isinstance(script, str):\n",
    "        return script or \"\"\n",
    "\n",
    "    s = script.strip()\n",
    "    # Drop a first line that is just the headline\n",
    "    lines = s.splitlines()\n",
    "    if lines and _norm_compact(lines[0]) == _norm_compact(headline):\n",
    "        s = \"\\n\".join(lines[1:]).lstrip()\n",
    "\n",
    "    # Drop leading patterns like 'Headline: ...' or 'Headline - ...'\n",
    "    s = re.sub(\n",
    "        rf\"(?is)^\\s*{re.escape(headline)}\\s*[:\\-–—]+\\s*\",\n",
    "        \"\",\n",
    "        s,\n",
    "    ).strip()\n",
    "\n",
    "    return s\n",
    "\n",
    "\n",
    "def dedupe_sentences(text: str) -> str:\n",
    "    \"\"\"Remove exact/near-exact sentence repetitions (helps with title rephrasing loops).\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    t = re.sub(r\"\\s+\", \" \", text.strip())\n",
    "    if not t:\n",
    "        return \"\"\n",
    "\n",
    "    parts = re.split(r\"(?<=[.!?])\\s+\", t)\n",
    "    seen: set[str] = set()\n",
    "    kept: list[str] = []\n",
    "    for p in parts:\n",
    "        s = p.strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        key = _norm_compact(s)\n",
    "        if not key or key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        kept.append(s)\n",
    "\n",
    "    return \" \".join(kept).strip()\n",
    "\n",
    "\n",
    "def generate_script(\n",
    "    slide_text: str,\n",
    "    output_lang: str,\n",
    "    minutes_per_page: float,\n",
    "    detail_style: str,\n",
    ") -> str:\n",
    "    \"\"\"Summarize ONE slide into narration text, used for TTS/video (single slide only).\"\"\"\n",
    "    if client is None:\n",
    "        raise RuntimeError(\"OpenAI client not initialized (OPENAI_API_KEY missing).\")\n",
    "\n",
    "    lang_code = normalize_lang(output_lang)\n",
    "    lang_name = LANG_MAP[lang_code]\n",
    "\n",
    "    minutes_per_page = clamp_minutes(minutes_per_page)\n",
    "    detail_style = normalize_detail_style(detail_style)\n",
    "    max_words = max_words_for_minutes(minutes_per_page, wpm=SPEECH_WPM)\n",
    "\n",
    "    slide_text = clean_page_text(slide_text)\n",
    "    headline = detect_slide_headline(slide_text)\n",
    "    slide_body = remove_headline_line(slide_text, headline)\n",
    "    if not slide_body.strip():\n",
    "        slide_body = slide_text\n",
    "    if not slide_body.strip():\n",
    "        slide_body = \"(No extractable text found on this slide.)\"\n",
    "\n",
    "    if detail_style == \"summary\":\n",
    "        style_hint = \"Summarize the key message and keep it essential.\"\n",
    "    else:\n",
    "        style_hint = \"Explain clearly with a bit more context.\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0.2,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are a professional narrator. \"\n",
    "                    \"You will receive the extracted content for EXACTLY ONE slide (one PDF page). \"\n",
    "                    f\"Write the speaker narration in {lang_name} ({lang_code}). \"\n",
    "                    \"IMPORTANT: Output ONLY the narration for THIS single slide. \"\n",
    "                    \"Do NOT include page/slide numbers, headings, or any meta text. \"\n",
    "                    \"Avoid repetition: do NOT repeat the slide headline/title verbatim, and do NOT start the narration by restating the headline. \"\n",
    "                    \"Do NOT say phrases like 'This slide is about ...' or 'The title is ...'. Start directly with the explanation. \"\n",
    "                    \"Do NOT mention other slides/pages, and do NOT add 'next slide' or continuations. \"\n",
    "                    \"Return plain narration text (full sentences), suitable for TTS. \"\n",
    "                    f\"Target duration: about {minutes_per_page:g} minute(s). \"\n",
    "                    f\"Hard limit: max {max_words} words. \"\n",
    "                    f\"Style: {detail_style}. \"\n",
    "                    f\"Guidance: {style_hint}\"\n",
    "                ),\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"SLIDE HEADLINE (do NOT repeat verbatim in narration):\\n\"\n",
    "                    + (headline or \"(unknown)\")\n",
    "                    + \"\\n\\nSLIDE BODY CONTENT (single slide only):\\n\"\n",
    "                    + slide_body\n",
    "                    + \"\\n\\nReturn ONLY the narration text for this slide.\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    script = response.choices[0].message.content or \"\"\n",
    "    script = sanitize_script_output(script)\n",
    "    script = remove_headline_echo(script, headline)\n",
    "    script = dedupe_sentences(script)\n",
    "    return truncate_to_word_limit(script, max_words=max_words)\n",
    "\n",
    "\n",
    "def generate_audio(text: str, filepath: str) -> None:\n",
    "    \"\"\"Generate an audio file using OpenAI TTS.\"\"\"\n",
    "    if client is None:\n",
    "        raise RuntimeError(\"OpenAI client not initialized (OPENAI_API_KEY missing).\")\n",
    "\n",
    "    with client.audio.speech.with_streaming_response.create(\n",
    "        model=TTS_MODEL,\n",
    "        voice=TTS_VOICE,\n",
    "        input=text,\n",
    "    ) as response:\n",
    "        response.stream_to_file(filepath)\n",
    "\n",
    "\n",
    "def process_workflow(\n",
    "    output_lang: str = OUTPUT_LANG,\n",
    "    minutes_per_page: float = TARGET_SPOKEN_MINUTES_PER_PAGE,\n",
    "    detail_style: str = DETAIL_STYLE,\n",
    ") -> None:\n",
    "    if not Path(INPUT_PDF_PATH).exists():\n",
    "        raise FileNotFoundError(f\"PDF not found: {INPUT_PDF_PATH}\")\n",
    "\n",
    "    output_lang = normalize_lang(output_lang)\n",
    "    minutes_per_page = clamp_minutes(minutes_per_page)\n",
    "    detail_style = normalize_detail_style(detail_style)\n",
    "\n",
    "    use_user_corrected = parse_yes_no(USE_USER_CORRECTED_TEXT, default=False)\n",
    "    force_regen_llm = parse_yes_no(FORCE_REGENERATE_LLM_TEXT, default=False)\n",
    "    create_user_templates = parse_yes_no(CREATE_USER_CORRECTION_TEMPLATES, default=True)\n",
    "\n",
    "    pages_dir = (Path(TEMP_DIR) / \"pages\").resolve()\n",
    "    scripts_llm_dir = (Path(TEMP_DIR) / LLM_SCRIPTS_SUBDIR).resolve()\n",
    "    scripts_user_dir = (Path(TEMP_DIR) / USER_SCRIPTS_SUBDIR).resolve()\n",
    "    scripts_used_dir = (Path(TEMP_DIR) / USED_SCRIPTS_SUBDIR).resolve()\n",
    "\n",
    "    pages_dir.mkdir(parents=True, exist_ok=True)\n",
    "    scripts_llm_dir.mkdir(parents=True, exist_ok=True)\n",
    "    scripts_user_dir.mkdir(parents=True, exist_ok=True)\n",
    "    scripts_used_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Safe cleanup: only clear \"used\" scripts (never delete LLM originals or user edits)\n",
    "    if CLEAN_OUTPUT_DIRS:\n",
    "        clear_dir_by_patterns(scripts_used_dir, [\"slide_*.txt\"])\n",
    "\n",
    "    slide_images = render_pdf_pages_to_images_pymupdf(\n",
    "        INPUT_PDF_PATH,\n",
    "        str(pages_dir),\n",
    "        dpi=PDF_DPI,\n",
    "        slide_start=SLIDE_START,\n",
    "        slide_end=SLIDE_END,\n",
    "        image_format=IMAGE_FORMAT,\n",
    "        jpg_quality=IMAGE_QUALITY,\n",
    "    )\n",
    "\n",
    "    # Resolve the actual clamped range for text extraction\n",
    "    try:\n",
    "        import fitz\n",
    "\n",
    "        doc = fitz.open(str(Path(INPUT_PDF_PATH).resolve()))\n",
    "        total_pages = doc.page_count\n",
    "        doc.close()\n",
    "    except Exception:\n",
    "        total_pages = None\n",
    "\n",
    "    if total_pages is not None:\n",
    "        start, end = clamp_slide_range(SLIDE_START, SLIDE_END, total_pages)\n",
    "    else:\n",
    "        start, end = SLIDE_START, (SLIDE_START + len(slide_images) - 1)\n",
    "\n",
    "    slide_texts = get_slide_texts_with_ocr_fallback(\n",
    "        INPUT_PDF_PATH,\n",
    "        slide_images=slide_images,\n",
    "        slide_start=start,\n",
    "        slide_end=end,\n",
    "        output_lang=output_lang,\n",
    "    )\n",
    "\n",
    "    clips = []\n",
    "\n",
    "    if not USE_OPENAI:\n",
    "        print(\n",
    "            \"Note: OPENAI_API_KEY is not set. Rendering a silent video \",\n",
    "            f\"({DEFAULT_PAGE_SECONDS}s per slide).\",\n",
    "        )\n",
    "    else:\n",
    "        max_words = max_words_for_minutes(minutes_per_page, wpm=SPEECH_WPM)\n",
    "        print(\n",
    "            f\"Output language: {output_lang} ({LANG_MAP[output_lang]}), \",\n",
    "            f\"target: {minutes_per_page:g} min/slide (~{max_words} words max), \",\n",
    "            f\"style: {detail_style}, \",\n",
    "            f\"use_user_corrected_text: {use_user_corrected}\",\n",
    "        )\n",
    "        llm_folder_short = (Path(TEMP_DIR) / LLM_SCRIPTS_SUBDIR).as_posix()\n",
    "        user_folder_short = (Path(TEMP_DIR) / USER_SCRIPTS_SUBDIR).as_posix()\n",
    "        print(f\"LLM originals folder: {llm_folder_short}\")\n",
    "        print(f\"User-corrected folder: {user_folder_short}\")\n",
    "\n",
    "    for i, img_path in enumerate(slide_images):\n",
    "        slide_number = start + i\n",
    "        print(f\"Processing slide {slide_number} ({i + 1}/{len(slide_images)})...\")\n",
    "\n",
    "        if USE_OPENAI:\n",
    "            llm_script_target = scripts_llm_dir / f\"slide_{slide_number:03d}.txt\"\n",
    "            user_script_path = scripts_user_dir / f\"slide_{slide_number:03d}.txt\"\n",
    "            used_script_path = scripts_used_dir / f\"slide_{slide_number:03d}.txt\"\n",
    "\n",
    "            user_text = read_text_or_empty(user_script_path)\n",
    "            if use_user_corrected and user_text.strip():\n",
    "                script = user_text.strip()\n",
    "                script_source = \"USER_CORRECTED\"\n",
    "            else:\n",
    "                existing_llm = read_text_or_empty(llm_script_target)\n",
    "                if existing_llm.strip() and not force_regen_llm:\n",
    "                    script = existing_llm.strip()\n",
    "                    script_source = \"LLM_ORIGINAL(existing)\"\n",
    "                else:\n",
    "                    script = generate_script(\n",
    "                        slide_texts[i],\n",
    "                        output_lang,\n",
    "                        minutes_per_page,\n",
    "                        detail_style,\n",
    "                    )\n",
    "                    saved_path = safe_write_text_no_overwrite(llm_script_target, script)\n",
    "                    if saved_path != llm_script_target:\n",
    "                        print(f\"  LLM original preserved (versioned): {saved_path.name}\")\n",
    "                    script_source = \"LLM_ORIGINAL(new)\"\n",
    "\n",
    "                if use_user_corrected and create_user_templates and not user_script_path.exists():\n",
    "                    try:\n",
    "                        user_script_path.write_text(script, encoding=\"utf-8\")\n",
    "                        print(f\"  Created user-correction template: {user_script_path.name}\")\n",
    "                    except OSError as exc:\n",
    "                        print(f\"  Warning: could not create user template: {exc}\")\n",
    "\n",
    "            if SAVE_SLIDE_TEXT:\n",
    "                used_script_path.write_text(script, encoding=\"utf-8\")\n",
    "\n",
    "            print(f\"  Script source: {script_source}\")\n",
    "\n",
    "            audio_path = str((Path(TEMP_DIR) / f\"audio_{slide_number:03d}.mp3\").resolve())\n",
    "            generate_audio(script, audio_path)\n",
    "\n",
    "            audio_clip = AudioFileClip(audio_path)\n",
    "            duration = audio_clip.duration\n",
    "        else:\n",
    "            duration = DEFAULT_PAGE_SECONDS\n",
    "            audio_clip = None\n",
    "\n",
    "        # This is the slide image shown in the final video\n",
    "        slide_clip = ImageClip(str(img_path)).with_duration(duration)\n",
    "        if audio_clip is not None:\n",
    "            slide_clip = slide_clip.with_audio(audio_clip)\n",
    "\n",
    "        clips.append(slide_clip)\n",
    "\n",
    "    print(\"Rendering video...\")\n",
    "    final_video = concatenate_videoclips(clips, method=\"compose\")\n",
    "    final_video.write_videofile(\n",
    "        OUTPUT_VIDEO,\n",
    "        fps=VIDEO_FPS,\n",
    "        codec=VIDEO_CODEC,\n",
    "        audio_codec=VIDEO_AUDIO_CODEC,\n",
    "        ffmpeg_params=VIDEO_FFMPEG_PARAMS,\n",
    "    )\n",
    "    print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fcbcf3",
   "metadata": {},
   "source": [
    "## Run workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d15ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run complete workflow\n",
    "if RUN_WORKFLOW:\n",
    "    process_workflow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
